# 《STATISTICAL-PREDICTION-AND-MACHINE-LEARNING》
- project-3
- 2024/5/27
  
**〈資料簡介〉**： 

　　本 project 利用來自葡萄牙北部的紅葡萄酒與白葡萄酒數據資料集，進行後續機器學習分析，該資料集旨在透過多種分類模型，根據其物理化學特性預測葡萄酒品質。大致操作流程包括：數據預處理、計算特徵間相關性、標籤處理（Labeling）、定義分類模型與評估指標，以及模型訓練與性能評估。該資料集來源於 UCI 機器學習數據庫，為公開且僅限研究用途的資源，適用於有序回歸、分類問題，或其他研究任務（如特徵選擇與異常值檢測），數據包含兩個子集：  
  
- **winequality-red.csv**：紅葡萄酒樣本，1599筆數據。  
- **winequality-white.csv**：白葡萄酒樣本，4898筆數據。  

　　每個數據集包括11個物理化學特徵（連續值）與 1 個整數品質評分（0-10分），總計 6497 筆數據，且無缺失值，以下對各特徵進行詳細說明，並推測其與葡萄酒品質的關係：

1. Fixed Acidity（固定酸度）
- 葡萄酒固定酸度主要由酒石酸、蘋果酸等有機酸構成。適量的酸度能夠提供葡萄酒清爽的口感，但過高的酸度會讓葡萄酒顯得過於尖銳，影響飲用感受。過低的酸度則會讓葡萄酒顯得平淡無味，其與品質之間的關係推測為：「中度的固定酸度通常對葡萄酒品質有正面影響，但過高或過低的固定酸度可能降低品質評分。」。

2. Volatile Acidity（揮發性酸度）
- 主要由乙酸（醋酸）組成，較高的揮發性酸度會導致葡萄酒有刺鼻的氣味，類似於醋的味道；適量的揮發性酸度可以增加複雜性，但過高會被視為缺陷，與品質之間可能關係推測為：「高揮發性酸度通常會降低葡萄酒品質，適量的揮發性酸度對品質有一定的提升作用。」

3. Citric Acid（檸檬酸）
- 檸檬酸是一種天然存在的有機酸，能夠提供葡萄酒清新的酸味，增加其口感的層次感，其與品質之間可能關係推測為：｢適量的檸檬酸對葡萄酒品質有正面影響，但其含量一般較低，不是影響品質的主要因素。」

4. Residual Sugar（殘留糖量）
- 殘留糖分是葡萄酒中未發酵的糖，會影響葡萄酒的甜度。甜葡萄酒和乾葡萄酒對糖分的需求不同。殘留糖分也能平衡葡萄酒中的酸度，其與品質之間可能關係推測為：「殘留糖分的量需要與葡萄酒的風格相匹配，適量的殘留糖分能提升葡萄酒的品質，但過多的殘留糖分會使葡萄酒顯得過甜。」

5. Chlorides（氯化物）
- 氯化物（主要是氯化鈉）會影響葡萄酒的味道，通常高含量的氯化物會使葡萄酒有鹹味，這在大多數情況下被認為是缺陷，低氯化物含量對葡萄酒品質有正面影響，高氯化物含量通常會降低葡萄酒品質。

6. Free Sulfur Dioxide（游離二氧化硫）
- 游離二氧化硫用於抑制微生物生長和防止氧化，但過高的二氧化硫會帶來不好的氣味和味道，適量的游離二氧化硫對葡萄酒品質有保護作用，但過高的游離二氧化硫會降低品質。

7. Total Sulfur Dioxide（總二氧化硫）
- 總二氧化硫包括游離和結合的二氧化硫，其作用與游離二氧化硫類似，主要是防腐和抗氧化，適量的總二氧化硫對葡萄酒品質有保護作用，但過高的總二氧化硫會降低品質。

8. Density（密度）
- 密度與葡萄酒的糖分、酒精含量有關，是衡量葡萄酒甜度和濃度的一個指標，其與品質之間可能關係推測為：「密度可以間接反映葡萄酒的殘留糖分和酒精含量，適當的密度對葡萄酒品質有正面影響，但過高的密度可能意味著過多的殘留糖分，過低的密度則可能導致酒體單薄。」

9. pH（酸鹼值）
- pH 值反映葡萄酒的酸鹼度，通常在 3 至 4 之間。pH 值過高會使葡萄酒缺乏酸度，過低會使其過於尖銳，適中的 pH 值（通常在 3.2 到 3.6 之間）有助於提高葡萄酒品質，過高或過低的 pH 值都會對品質產生負面影響。

10. Sulphates（硫酸鹽）
- 硫酸鹽在發酵過程中自然產生，適量的硫酸鹽能夠穩定葡萄酒的風味和顏色，對葡萄酒品質有正面影響，過多的硫酸鹽可能會產生苦味，影響品質。

11. Alcohol（酒精）
- 酒精含量是葡萄酒的一個重要品質指標，對其風味、酒體和感官評價有重要影響，適度的酒精含量能夠提升葡萄酒的風味和酒體，對葡萄酒品質有正面影響，過高的酒精含量會使葡萄酒顯得過於辛辣，過低的酒精含量則可能使酒體單薄。

12. Quality（品質評分）
- 整數評分（0-10），為目標變數 y，作為分類或回歸任務的依據，評估特徵與品質的關聯性，受上述11個物理化學特徵綜合影響，可透過機器學習模型預測與分析。

**〈分析結果〉：**

**變更前後結果比較**

| **模型** | **移除 `type` 前 - Accuracy** | **移除 `type` 後 - Accuracy** | **變化** |
|----------|-------------------|-------------------|--------|
| **Logistic Regression** | 0.7400 | 0.7415 | **+0.0015** |
| **LDA** | 0.7400 | 0.7423 | **+0.0023** |
| **QDA** | 0.7146 | 0.7162 | **+0.0016** |
| **K-NN (k=5)** | 0.7500 | 0.7492 | **-0.0008** |

| **模型** | **移除 `type` 前 - F1 Score** | **移除 `type` 後 - F1 Score** | **變化** |
|----------|-------------------|-------------------|--------|
| **Logistic Regression** | 0.8030 | 0.8040 | **+0.0010** |
| **LDA** | 0.8030 | 0.8044 | **+0.0014** |
| **QDA** | 0.7867 | 0.7888 | **+0.0021** |
| **K-NN (k=5)** | 0.8083 | 0.8078 | **-0.0005** |


**1. 大部分模型的表現略有提升（特別是 LDA、QDA）**
   - **LDA 的 Accuracy +0.23%，F1 Score +0.14%**
   - **QDA 的 Accuracy +0.16%，F1 Score +0.21%**

**2. K-NN 表現幾乎不變，甚至稍微下降**
   - **Accuracy 下降 0.08%，F1 Score 下降 0.05%**，這表示 K-NN 可能更依賴 `type` 作為分類特徵。
   - 由於 K-NN 是基於鄰近點的距離來進行分類，`type` 提供了「紅酒 vs. 白酒」的額外區分資訊，移除後影響較其他模型更明顯。

**3. 移除 `type` 整體提升了分類器的泛化能力**
- **LDA、Logistic Regression、QDA 都有所改善**，表示 `type` 可能是個「**捷徑特徵（Shortcut Feature）**」使得模型過度依賴葡萄酒的類別，而非根據化學特性進行分類。

**4. 移除 `type` 之後，結果變得更可靠，更能反映酒的內在特徵。**



**〈K-NN 選擇最佳 K 值〉**

![image](https://github.com/user-attachments/assets/86ddb3d3-4558-42c2-97ba-cf7722566984)

**1. K=1 的 Accuracy 最高，但可能 Overfitting**，K 值太小模型過度依賴鄰近的單一數據點，導致泛化能力下降，通常不會選擇作為最終模型，**應避免 K=1 或 K=2**。

**2. K=7, K=9 是最佳的選擇：**
- 從 Accuracy 和 F1 Score 綜合考量，**K=7、K=9** 表現良好，**F1 Score 最高 (0.816, 0.817)**，代表 Precision 和 Recall 維持最佳平衡；**Accuracy 也很高 (0.758, 0.759)** 泛化能力較佳：

- **K=7**:
  - Accuracy = 0.758
  - Precision = 0.788
  - Recall = 0.845
  - F1 Score = 0.816
- **K=9**:
  - Accuracy = 0.759
  - Precision = 0.786
  - Recall = 0.851
  - F1 Score = 0.817

**3. K > 10 後模型表現穩定**
從 K=10 開始，Accuracy 約落在 **0.752~0.757**，F1 Score 約 **0.810~0.815**，變動不大：
- **K=15~K=20** 的 Accuracy 幾乎沒有顯著提升。
- **Recall 在 K > 15 後保持在 0.83~0.85**，但 Precision 稍微下降。
- **較大的 K 值（15 以上）模型已經趨於平穩，沒有顯著提升表現**，反而可能過度平滑，使模型對少數類別的區分能力下降。

**4. 最理想的是 Precision 和 Recall 平衡，避免過度偏向其中之一：**
- **Precision 較高的 K 值**（K=1, 5, 7, 10），代表模型較謹慎，避免誤判「好酒」。
- **Recall 較高的 K 值**（K=9, 11, 17），代表模型能夠找到更多「好酒」，但可能會有較多誤判。
